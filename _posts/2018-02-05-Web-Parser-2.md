---
list_title: 写一个Web端的解释器（二） | Let's Build a Parser By Hand | Lexical Analysis
title: 词法分析
layout: post
mathjax: true;
---

### Prerequist Knowledge

- [Lexcial Analysis]()
- [Python Lex-Yacc](https://github.com/dabeaz/ply)



### Lexer

关于什么是[Lexer]()，可以参考之前编译原理的文章，Python提供了一个Lexer的类库`ply`，可以方便的将句子切分成token，但有几点需要注意。首先是匹配token的顺序和优先级，比如匹配WORD的正则式为`r'[^ <>]+'`，匹配string的正则式为`r'"[^"]+"'`，对于下字符`hello "world"`,如果WORD的正则在前，则匹配的结果为 [WORD, WORD]，如果STRING在前，则匹配的结果为[WORD, STRING]。另一问题是不同状态机的互斥，例如，代码注释可以穿插在代码中，对注释的解析需要令一个的状态机，和解析HTML Token的状态机互斥，例如下面的代码

```HTML
 webpage = '''Welcome to <b>my <!-- careful </b> --> webpage</b>'''
```

当遇见`<!--`时，进入解析注释的状态机，并将结果排除在Token之外

![](/assets/images/2015/07/lexer-1.png)

### HTML Lexer

附录为所有HMTL的Token，使用`ply`可以将其HTML代码切分为Token，并忽略掉注释，得到的token如下所示

<div class="md-flex-h md-margin-bottom-20">
<div>
<pre class="highlight language-python md-no-padding-v md-height-full">
<code class="language-python">

htmllexer = lex.lex()
htmllexer.input(webpage)
while True:
    #return next token
    tok = htmllexer.token() 
    if not tok: 
        break
    print(tok)
</code>
</pre>
</div>
<div class="md-margin-left-12">
<pre class="highlight md-no-padding-v md-height-full">
<code class="language-python">
LexToken(WORD,'This',1,0)
LexToken(WORD,'is',1,5)
LexToken(LANGLE,'<',2,26)
LexToken(WORD,'b',2,27)
LexToken(RANGLE,'>',2,28)
LexToken(WORD,'my',2,29)
LexToken(LANGLESLASH,'</',2,31)
LexToken(WORD,'b',2,33)
LexToken(RANGLE,'>',2,34)
LexToken(WORD,'webpage!',2,36)
</code>
</pre>
</div>
</div>


