---
list_title: 写一个Web解释器 | Build a Parser By Hand | 词法分析| Lexical Analysis
title: 词法分析
layout: post
mathjax: true
categories: [Parser,Compiler]
---

### Prerequist Knowledge

- Automata Theory
    - Finite State Machine
    - Formal Language
    - Regular Language
    - Context Free Grammar
    - DFA / NFA
- [Lexcial Analysis]()
- Algorithms
    - Recursion
- Tools
    - Python Syntax
    - [Python Lex-Yacc](https://github.com/dabeaz/ply)
    - Regular Expression




### DFA/NFA 

正则式`r='a+1+'`的FSM为：

<img class="md-img-center" src="{{site.baseurl}}/assets/images/2015/07/fsm-1.png">

上述FSM用python可以表示如下：

```python
edges = {
    (1,'a') : 2, #state#1 takes an input of 'a', transfer the state to #2
    (2,'a') : 2,
    (2,'1') : 3,
    (3,'1') : 3
}
```
接下来，我们要设计一个状态转移函数，参考之前计算理论或者编译原理的文章，一个DFA至少要包含：

1. 一个确定的状态集合，用 $Q$ 表示
2. 一组输入的字符，用 $\sum$ 表示
3. 一个状态转移函数（正则表达式），用 $\delta$ 表示
4. 一个初始状态，用 $q_0 表示，$q_0$ 属于 $Q$ 的一部分
5. 一组最终状态，用 $F$ 表示，$F \subseteq Q$
    - 叫Final State，也可以叫Accepting State


对于状态转移函数，需要接受一个输入字符串，和其实状态id，参照上面的状态机来判断输入字符是否能被状态机接受

```python
accepting = [3] #状态机的结束状态，可能有多个结束状态，用array表示
def fsmsim(string, current, edges, accepting):
    if string == "":
        return current in accepting
    else:
        letter = string[0]
        key = (current,letter)
        if key in edges:
            next_state = edges[key]
            remaining_string = string[1:]
            return fsmsim(remaining_string,next_state,edges,accepting)
        else:
            return False;

print(fsmsim("aaa111",1,fsm,accepting)) #=>True 
print(fsmsim("a1a1a1",1,fsm,accepting)) #=>Flase
print(fsmsim("",1,fsm,accepting)) #=>Fals
```
回顾一下上面的过程，其思路为:

1. 由正则式 ---> FSM状态机 ---> 用`map<tuple<int,char>,int>`表示
2. 设计`fsmsim`函数，解析输入字符串
3. 观察是否匹配正则式（能被状态机接受）

接下来再来看几个例子，假如正则式换为`r"q*"`，修改FSM状态机和Accept State为：

<img class="md-img-center" src="{{site.baseurl}}/assets/images/2015/07/fsm-2.png">

```python
edges = {
    (1,'q'):1
}
accepting = [1]

print fsmsim("",1,edges,accepting)# >>> True
print fsmsim("q",1,edges,accepting)# >>> True
print fsmsim("qq",1,edges,accepting)# >>> True
print fsmsim("p",1,edges,accepting)# >>> False
```

接下来再来看几个例子，假如正则式换为`r"[a-b][c-d]?"`，修改FSM状态机和Accept State为：

<img class="md-img-center" src="{{site.baseurl}}/assets/images/2015/07/fsm-3.png">

```python
edges = {
    (1,'a'):2,
    (1,'b'):2,
    (2,'c'):3,
    (2,'d'):3
}
accepting = [2,3]
print fsmsim("a",1,edges,accepting)# >>> True
print fsmsim("b",1,edges,accepting)# >>> True
print fsmsim("ad",1,edges,accepting)# >>> True
print fsmsim("e",1,edges,accepting)# >>> False
```

Python的`re`库对正则表达式解析和`fsmsim`类似，但是上面的fsmsim函数只是实现DFA,没有考虑NFA，具体来说有下面两种情况没有考虑

1. Ambiguity
2. $\epsilon$ 状态

考虑下面NFA，输入字符串为`1-23`

<img class="md-img-center" src="{{site.baseurl}}/assets/images/2015/07/fsm-4.png">

1. 从状态起始点1开始，输入字符为`1`，走到状态2
2. 由于有$\epsilon$ 状态，转态2可以直接转化为状态3
3. 状态3读入`-`进入状态4
4. 状态4读入`2`进入状态5
5. 状态5读入`3`之后，产生Ambiguity，一种可能是回到状态2，一种可能是回到状态3

不难想到，产生Ambiguity的一个原因是正则式里存在"或"，例如`regex=r'a+|ab+c'`，由于有`|`，因此第一个状态后就出现了分支

<img class="md-img-center" src="{{site.baseurl}}/assets/images/2015/07/fsm-6.png">

回忆前面对FMS的python描述，每一组<状态,输入>的Tuple对应唯一个next state，对于NFA，next state可能有多个，我们只需要遍历所有的可能状态即可

```python
edges = { (1, 'a') : [2, 3],
          (2, 'a') : [2],
          (3, 'b') : [4, 3],
          (4, 'c') : [5] }
accepting = [2, 5] 

def nfsmsim(string, current, edges, accepting): 
    if(string==""):
        return current in accepting
    else:
        letter = string[0]
        key = (current,letter)
        if key in edges:
            next_states = edges[key]
            for state in next_states:
                remain_str = string[1:]
                #只有当nfsmsim为true 才返回，false继续尝试
                if nfsmsim(remain_str,state,edges,accepting):
                    return True
        
        return False

# test case
print "Test case 1 passed: " + str(nfsmsim("abc", 1, edges, accepting) == True) 
print "Test case 2 passed: " + str(nfsmsim("aaa", 1, edges, accepting) == True) 
print "Test case 3 passed: " + str(nfsmsim("abbbc", 1, edges, accepting) == True) 
print "Test case 4 passed: " + str(nfsmsim("aabc", 1, edges, accepting) == False) 
print "Test case 5 passed: " + str(nfsmsim("", 1, edges, accepting) == False) 
```

参考之前计算理论的文章可知，对所有NFA都可以转化而为DFA，下图NFA对应的正则表达式为`regexr = "ab?c" `

<img class="md-img-center" src="{{site.baseurl}}/assets/images/2015/07/fsm-5.png">

左边的NFA是对上述正则表达式的一种很直观的实现，右边是与其等价的DFA，它将所有通过`epsilon`所到达的状态进行了合并，解决了上述两个问题。

- **小结**

1. string是一组字符的合集
2. 每个Regular Expression对应一个DFA，反之亦然
3. NFA可以转化为DFA
4. 使用`fsmsim`函数来实现regular expression的解析

在实际的解析过程中，我们几乎不会用到`fsmsim`函数，而是直接使用正则表达式，但了解其如何工作的对理解Parser很重要，接下来我们将讨论如何如何实现词法分析，将表达式切分成token

### 词法分析器

了解了正则表达式的计算原理，我们就可以同它来实现词法分析器。关于什么是Lexer，可以参考之前编译原理的文章，Python提供了一个Lexer的类库`ply`，可以方便的将句子切分成token，但有几点需要注意：
1. 首先是匹配token的顺序和优先级，比如匹配WORD的正则式为`r'[^ <>]+'`，匹配string的正则式为`r'"[^"]+"'`，对于下字符`hello "world"`,如果WORD的正则在前，则匹配的结果为 [WORD, WORD]，如果STRING在前，则匹配的结果为[WORD, STRING]。
2. 另一问题是不同状态机的互斥，例如，代码注释可以穿插在代码中，对注释的解析需要令一个的状态机，和解析HTML Token的状态机互斥，例如下面的代码

```HTML
 webpage = '''Welcome to <b>my <!-- careful </b> --> webpage</b>'''
```

当遇见`<!--`时，进入解析注释的状态机，并将结果排除在Token之外

![](/assets/images/2015/07/lexer-1.png)

### HTML Lexer

这一节我们以HTML文本为例，来实现一个简单的lexer，首先我们可以根据HTML的标签规则生成一组tokens:

```python
tokens = (
    'LANGLE', # <
    'LANGLESLASH', #</
    'RANGLE', #>
    'EQUAL', #=
    'STRING', #"hello"
    'WORD' #welcome!
)
```
然后对每个token，我们可以按照`ply`的规则给出匹配的正则式，这里特比要注意前面提到的第二点，`ply`默认由上到下匹配，一旦命中匹配规则，则会立即返回，不会继续向下匹配。由于篇幅原因，这里不会列出所有的token

```python
# HTML Tokens
def t_LANGLESLASH(token):
    r'</'
    return token

def t_LANGLE(token):
    r'<'
    return token
#...

def t_newline(token):
    r'\n'
    token.lexer.lineno += 1
    pass
```
有了token的正则式，我们便可以用`ply`内部的方法，HTML代码token化：

<div class="md-flex-h md-margin-bottom-24">
<div>
<pre class="highlight language-python md-no-padding-v md-height-full">
<code class="language-python">

htmllexer = lex.lex()
htmllexer.input(webpage)
while True:
    #return next token
    tok = htmllexer.token() 
    if not tok: 
        break
    print(tok)
</code>
</pre>
</div>
<div class="md-margin-left-12">
<pre class="highlight md-no-padding-v md-height-full">
<code class="language-python">
LexToken(WORD,'This',1,0)
LexToken(WORD,'is',1,5)
LexToken(LANGLE,'<',2,26)
LexToken(WORD,'b',2,27)
LexToken(RANGLE,'>',2,28)
LexToken(WORD,'my',2,29)
LexToken(LANGLESLASH,'</',2,31)
LexToken(WORD,'b',2,33)
LexToken(RANGLE,'>',2,34)
LexToken(WORD,'webpage!',2,36)
</code>
</pre>
</div>
</div>





{% include _partials/post-footer-1.html %}